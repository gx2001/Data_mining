{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χατζηλίγος Γιώργος 4835 με 2 free passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('Census_Data_cleaned_sample.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make of target (y) and features (X)\n",
    "\n",
    "\n",
    "df['target'] = (df['income'] > 50000).astype(int)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['income', 'target'])  # όλα τα υπόλοιπα πεδία\n",
    "y = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict = X.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "X_transformed = vec.fit_transform(X_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== Results ==============================\n",
      "           Classifier  Accuracy  Precision    Recall\n",
      "0        DecisionTree   0.72740   0.706374  0.706161\n",
      "1                 kNN   0.76080   0.742446  0.738508\n",
      "2  LogisticRegression   0.77515   0.760990  0.743906\n",
      "3                 SVM   0.70610   0.687121  0.646919\n",
      "4                 MLP   0.75720   0.741166  0.722473\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),  \n",
    "    'recall': make_scorer(recall_score, average='macro')\n",
    "}\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=0)\n",
    "knn = KNeighborsClassifier()\n",
    "logistic_regression = LogisticRegression(solver='liblinear', random_state=0)\n",
    "svm = SVC(random_state=0)\n",
    "mlp = MLPClassifier(solver='lbfgs',max_iter=10000, random_state=0)\n",
    "\n",
    "\n",
    "#------------ Begin of Classifiers --------------#\n",
    "\n",
    "# 4.1. Decision Tree\n",
    "cv_scores_dt = cross_validate(\n",
    "    estimator=decision_tree,\n",
    "    X=X_transformed,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "dt_accuracy_mean = np.mean(cv_scores_dt['test_accuracy'])\n",
    "dt_precision_mean = np.mean(cv_scores_dt['test_precision'])\n",
    "dt_recall_mean    = np.mean(cv_scores_dt['test_recall'])\n",
    "\n",
    "# 4.2. kNN\n",
    "cv_scores_knn = cross_validate(\n",
    "    estimator=knn,\n",
    "    X=X_transformed,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "knn_accuracy_mean = np.mean(cv_scores_knn['test_accuracy'])\n",
    "knn_precision_mean = np.mean(cv_scores_knn['test_precision'])\n",
    "knn_recall_mean    = np.mean(cv_scores_knn['test_recall'])\n",
    "\n",
    "# 4.3. Logistic Regression\n",
    "cv_scores_logistic_regression = cross_validate(\n",
    "    estimator=logistic_regression,\n",
    "    X=X_transformed,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "logistic_regression_accuracy_mean = np.mean(cv_scores_logistic_regression['test_accuracy'])\n",
    "logistic_regression_precision_mean = np.mean(cv_scores_logistic_regression['test_precision'])\n",
    "logistic_regression_recall_mean    = np.mean(cv_scores_logistic_regression['test_recall'])\n",
    "\n",
    "# 4.4. SVM\n",
    "cv_scores_svm = cross_validate(\n",
    "    estimator=svm,\n",
    "    X=X_transformed,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "svm_accuracy_mean = np.mean(cv_scores_svm['test_accuracy'])\n",
    "svm_precision_mean = np.mean(cv_scores_svm['test_precision'])\n",
    "svm_recall_mean    = np.mean(cv_scores_svm['test_recall'])\n",
    "\n",
    "# 4.5. MLP\n",
    "cv_scores_mlp = cross_validate(\n",
    "    estimator=mlp,\n",
    "    X=X_transformed,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "mlp_accuracy_mean = np.mean(cv_scores_mlp['test_accuracy'])\n",
    "mlp_precision_mean = np.mean(cv_scores_mlp['test_precision'])\n",
    "mlp_recall_mean    = np.mean(cv_scores_mlp['test_recall'])\n",
    "\n",
    "\n",
    "#------------ End of Classifiers --------------#\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append({\n",
    "    'Classifier': 'DecisionTree',\n",
    "    'Accuracy': dt_accuracy_mean,\n",
    "    'Precision': dt_precision_mean,\n",
    "    'Recall': dt_recall_mean\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Classifier': 'kNN',\n",
    "    'Accuracy': knn_accuracy_mean,\n",
    "    'Precision': knn_precision_mean,\n",
    "    'Recall': knn_recall_mean\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Classifier': 'LogisticRegression',\n",
    "    'Accuracy': logistic_regression_accuracy_mean,\n",
    "    'Precision': logistic_regression_precision_mean,\n",
    "    'Recall': logistic_regression_recall_mean\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Classifier': 'SVM',\n",
    "    'Accuracy': svm_accuracy_mean,\n",
    "    'Precision': svm_precision_mean,\n",
    "    'Recall': svm_recall_mean\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Classifier': 'MLP',\n",
    "    'Accuracy': mlp_accuracy_mean,\n",
    "    'Precision': mlp_precision_mean,\n",
    "    'Recall': mlp_recall_mean\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"========================== Results ==============================\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σχολιασμος Αποτελεσματων \n",
    "\n",
    "Accuracy = (Αρ.Σωστων Προβλεψεων) / (Συνολικος Αριθμος Δειγματων)\n",
    "\n",
    "Precision = (True Positive) / (True Positive + False Positive)\n",
    "\n",
    "Recall = True Positive) / (True Positive + False Negatives)\n",
    "\n",
    "Γενικοτερη Ερμηνεια των Αποτελεσματων \n",
    "\n",
    "\n",
    "\n",
    "1.DecisionTree : \n",
    "\n",
    "Accuracy  : το μοντελο ταξινομει σωστα το 72%\n",
    "\n",
    "Precision :το να προλεψει καποιον που εχει εισοδημα ανω 50Κ εχει ποσοστο 70%     \n",
    "\n",
    "Recall: απο ολους αυτους που οντως εχουν ειδοδημα ανω 50Κ εχει ποσοστο 70%\n",
    "\n",
    "\n",
    "2.kNN:\n",
    "\n",
    "Accuracy  : το μοντελο ταξινομει σωστα το 75.96% το δευτερο μεγαλυτερο ποσοστο\n",
    "\n",
    "Precision :το να προλεψει καποιον που εχει εισοδημα ανω 50Κ εχει ποσοστο 74.08% δηλαδη η προβλεψη θα ισχυει για αυτο το ποσοστο \n",
    "\n",
    "Recall: Αναγνωριζει απο ολους αυτους που οντως εχουν ειδοδημα ανω 50Κ το 73.79%\n",
    "\n",
    "\n",
    "3.LogisticRegression:\n",
    "\n",
    "Accuracy  : το μοντελο ταξινομει σωστα το 77.295% εχει το μεγαλυτερο ποσοστο\n",
    "\n",
    "Precision :το να προλεψει καποιον που εχει εισοδημα ανω 50Κ εχει ποσοστο 75.88% δηλαδη η προβλεψη θα ισχυει για αυτο το ποσοστο αρκετα ικανοποιητικο\n",
    "\n",
    "Recall: Αναγνωριζει απο ολους αυτους που οντως εχουν ειδοδημα ανω 50Κ το 73.07%\n",
    "\n",
    "\n",
    "\n",
    "4.SVM:\n",
    "\n",
    "Accuracy  : το μοντελο ταξινομει σωστα το 70.601% \n",
    "\n",
    "Precision :το να προλεψει καποιον που εχει εισοδημα ανω 50Κ εχει ποσοστο 68.7% δηλαδη η προβλεψη θα ισχυει για αυτο το ποσοστο \n",
    "\n",
    "Recall: Αναγνωριζει απο ολους αυτους που οντως εχουν ειδοδημα ανω 50Κ το 64.7%\n",
    "\n",
    "\n",
    "\n",
    "5.MLP:\n",
    "\n",
    "Accuracy  : το μοντελο ταξινομει σωστα το 72% \n",
    "\n",
    "Precision :το να προλεψει καποιον που εχει εισοδημα ανω 50Κ εχει ποσοστο 73% δηλαδη η προβλεψη θα ισχυει για αυτο το ποσοστο \n",
    "\n",
    "Recall: Αναγνωριζει απο ολους αυτους που οντως εχουν ειδοδημα ανω 50Κ το 69%\n",
    "\n",
    "\n",
    "Την καλυτερη αποδοση την εχει ο LogisticRegression με τις τρεχουσες ρυθμισεις που εχω διοτι μπορει το προβλημα να ειναι γραμμικο και οι μετρικες precision και recall ειναι σχετικα κοντα η μια με τη αλλη "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Επισης εγιναν και δοκιμες για μεγαλυτερο n_splits = 10  για περισσοτερες επαναληψεις σε mlp με διαφορετα settings, τροποποιησεις χωρις μεγαλες αλλαγες που θα μπορουσαν να επιρεασουν το αποτελεσμα οπως average='macro' χωρις να επηρεασουν τα accuracy , precision και recall με αποτελεσματα: \n",
    "========================== Results ==============================\n",
    "           Classifier  Accuracy  Precision   Recall\n",
    "0        DecisionTree   0.73310   0.733864  0.73310\n",
    "1                 kNN   0.76025   0.758540  0.76025\n",
    "2  LogisticRegression   0.77305   0.769196  0.77305\n",
    "3                 SVM   0.70630   0.697186  0.70630\n",
    "4                 MLP   0.75635   0.751977  0.75635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== Classifiers ==============================\n",
      "          Classifier  Accuracy  Precision    Recall\n",
      "0      RandomForest    0.76115   0.768544  0.702114\n",
      "1  GradientBoosting    0.79695   0.783904  0.771897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro')\n",
    "}\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    min_samples_split=5,\n",
    "    random_state=20\n",
    ")\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=1,\n",
    "    random_state=20\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_classifier(classifier, classifier_name):\n",
    "    cv_scores = cross_validate(\n",
    "        estimator=classifier,\n",
    "        X=X_transformed,\n",
    "        y=y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    acc_mean   = np.mean(cv_scores['test_accuracy'])\n",
    "    prec_mean  = np.mean(cv_scores['test_precision'])\n",
    "    rec_mean   = np.mean(cv_scores['test_recall'])\n",
    "    \n",
    "    return {\n",
    "        'Classifier': classifier_name,\n",
    "        'Accuracy': acc_mean,\n",
    "        'Precision': prec_mean,\n",
    "        'Recall': rec_mean\n",
    "    }\n",
    "\n",
    "#RandomForest\n",
    "res_randomforest = evaluate_classifier(random_forest, \"RandomForest \")\n",
    "\n",
    "#GradientBoosting\n",
    "res_gradient = evaluate_classifier(gradient_boosting, \"GradientBoosting \")\n",
    "\n",
    "res = [res_randomforest, res_gradient]\n",
    "res_df = pd.DataFrame(res)\n",
    "print(\"========================== Classifiers ==============================\")\n",
    "print(res_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δυο ακομη Classifiers που χρησιμοπιηθηκαν για καλυτερη αποδοση στο προβλημα ηταν \n",
    "\n",
    "1.RandomForest ο οποιος δημιουργει δεντρα αποφασης και λαμβανει αυτη μεσω πλειοψηφιας ψηφου\n",
    "και εκπαιδευει τα δεδομενα σε υποσυνολα .\n",
    "\n",
    "2.GradientBoosting ο οποιος οπου χτιζει δεντρα για να βελτιωσει τα λαθη του προηγουμενου\n",
    "\n",
    "Επισης θα μπορουσαμε να χρησιμοποιησουμε και αλλους classifiers που μοιαζουν να πετυχαινει καλυτερη αποδοση με γραμμικους Classifiers απο τα παραπανω αποτελεσματα . Δοκιμασα και τον Ridge και τον LDA χωρις ομως να δω καποια σπουδαια αλλαγη οι οποιοι λυνουν με καλυτερη αποδοση γραμμικα προβληματα.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gx2001/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== Results ============================\n",
      "  Classifier  Accuracy  Precision   Recall\n",
      "0       MLP    0.73515   0.744824  0.73515\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted')\n",
    "}\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    solver='adam',\n",
    "    hidden_layer_sizes=(60,50,40),\n",
    "    alpha=0.1,\n",
    "    activation='relu',\n",
    "    max_iter=10000,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "\n",
    "cv_scores_mlp_mod = cross_validate(\n",
    "    estimator=mlp,\n",
    "    X=X_transformed,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "mlp_accuracy = np.mean(cv_scores_mlp_mod['test_accuracy'])\n",
    "mlp_precision = np.mean(cv_scores_mlp_mod['test_precision'])\n",
    "mlp_recall = np.mean(cv_scores_mlp_mod['test_recall'])\n",
    "\n",
    "\n",
    "res_mlp = {\n",
    "    'Classifier': 'MLP ',\n",
    "    'Accuracy': mlp_accuracy,\n",
    "    'Precision': mlp_precision,\n",
    "    'Recall': mlp_recall\n",
    "}\n",
    "\n",
    "print(\"========================== Results ============================\")\n",
    "print(pd.DataFrame([res_mlp]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εκανα δοκιμη για ενα πιο βαθυ νευρωνικο δικτυο με τροποποιησεις αρχικα στους νευρωνες (πχ [10 , 20] , [10 , 20 ,10] κτλπ), επειτα στο βαθος του (πχ με 2,3,4 κρυφα επιπεδα) και διαφορετικους solvers και activation οπως relu και tanh συναρτησεις οπως adam και και το αποτελεσματα δεν ηταν τοσο ικανοποιητικα οπως φαινεται "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
